{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialization",
   "id": "90c7db4e01f7db3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:10:31.886107Z",
     "start_time": "2024-08-08T09:10:31.730578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Mnist data loading",
   "id": "a2d2777132e2216"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:23:23.162175Z",
     "start_time": "2024-08-08T08:22:51.070134Z"
    }
   },
   "cell_type": "code",
   "source": "(X_train, y_train), (X_test, y_test) = mnist.load_data()",
   "id": "cbf7e2aee2be5ed2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 29s 3us/step\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:24:01.423830Z",
     "start_time": "2024-08-08T08:24:01.404294Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.max()",
   "id": "183bca13be752db4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:25:46.059625Z",
     "start_time": "2024-08-08T08:25:45.900873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ],
   "id": "e095adb51fc3ce9e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:25:51.490187Z",
     "start_time": "2024-08-08T08:25:51.472915Z"
    }
   },
   "cell_type": "code",
   "source": "X_train",
   "id": "67c220856b942774",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:29:06.361922Z",
     "start_time": "2024-08-08T08:29:06.232150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "plt.imshow(X_train[154].reshape(28, 28))"
   ],
   "id": "cc9c828ccdcd0ba0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x196df26d7b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcJklEQVR4nO3df3DU9b3v8dcmkAU0WQwx2UQChh9CKxAthTQHpVgykPReB4Q/8Me5FxwvDBo8hdTqpKMgbWfS4lzq1ZPCzJkWtCNoOUfgyDkXLwQTxhpoiXAoR5tLMqnAIQmV22RDkBDI5/7Bce1KAn6X3byT8HzMfGfI7ved74cvq0++ZPONzznnBABAL0uwXgAA4OZEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIlB1gv4sq6uLp0+fVrJycny+XzWywEAeOScU1tbm7KyspSQ0PN1Tp8L0OnTp5WdnW29DADADTp58qRGjhzZ4/N9LkDJycmSpPv0XQ3SYOPVAAC8uqROva9/Df//vCdxC1B5ebleeuklNTU1KTc3V6+++qqmT59+3bnP/9ltkAZrkI8AAUC/8593GL3el1Hi8iaEt956SyUlJVqzZo0+/PBD5ebmau7cuTpz5kw8DgcA6IfiEqD169dr6dKlevzxx/X1r39dGzdu1LBhw/SrX/0qHocDAPRDMQ/QxYsXVVNTo4KCgi8OkpCggoICVVdXX7V/R0eHQqFQxAYAGPhiHqBPP/1Uly9fVkZGRsTjGRkZampqumr/srIyBQKB8MY74ADg5mD+jailpaVqbW0NbydPnrReEgCgF8T8XXBpaWlKTExUc3NzxOPNzc0KBoNX7e/3++X3+2O9DABAHxfzK6CkpCRNnTpVFRUV4ce6urpUUVGh/Pz8WB8OANBPxeX7gEpKSrR48WJ985vf1PTp0/Xyyy+rvb1djz/+eDwOBwDoh+ISoEWLFunPf/6zVq9eraamJt1zzz3avXv3VW9MAADcvHzOOWe9iL8WCoUUCAQ0S/O4EwIA9EOXXKcqtVOtra1KSUnpcT/zd8EBAG5OBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARMwD9OKLL8rn80VsEydOjPVhAAD93KB4fNK7775be/fu/eIgg+JyGABAPxaXMgwaNEjBYDAenxoAMEDE5WtAx48fV1ZWlsaMGaPHHntMJ06c6HHfjo4OhUKhiA0AMPDFPEB5eXnavHmzdu/erQ0bNqihoUH333+/2traut2/rKxMgUAgvGVnZ8d6SQCAPsjnnHPxPEBLS4tGjx6t9evX64knnrjq+Y6ODnV0dIQ/DoVCys7O1izN0yDf4HguDQAQB5dcpyq1U62trUpJSelxv7i/O2D48OG66667VFdX1+3zfr9ffr8/3ssAAPQxcf8+oHPnzqm+vl6ZmZnxPhQAoB+JeYCeeeYZVVVV6U9/+pM++OADPfTQQ0pMTNQjjzwS60MBAPqxmP8T3KlTp/TII4/o7Nmzuv3223XffffpwIEDuv3222N9KABAPxbzAL355pux/pQAgAGIe8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACbi/gPpMHAlDBvmfSbQ809H7MnHpaM9z7jBcf1BvxFSMrv/cfPX8m/Tt3qe+cvl855n/va+RZ5nJOnSJyejmgO84AoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgbNpQ4fkxUc83rvb98DnzD+12ge9OrfxnveWbTa4WeZyb/9inPM7cdv+R5Zugnv/M805sSJ4zzPFP34i2eZwYf9T4jSSPLPohqDl8NV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRjrAJN52m+eZe35TF9Wx1qYfjmrOqx805Xmeef8X06I6Vnr1Wc8zWR8NvBtWdhZM9Txzck6S55l7/+b/ep7595y3PM/cdWGZ5xnEH1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkbahyWmpHie+Y9NQc8zO9P3ep6RpPc+G+J55vkf/w/PM6lv/N7zzIhL1Z5nJOlyVFO9I3H8GM8zlzdejOpY/3viRs8zCb3099mjF73/KU34+wtRHctFNYWviisgAIAJAgQAMOE5QPv379eDDz6orKws+Xw+7dixI+J555xWr16tzMxMDR06VAUFBTp+/His1gsAGCA8B6i9vV25ubkqLy/v9vl169bplVde0caNG3Xw4EHdcsstmjt3ri5ciO7fYAEAA5PnNyEUFRWpqKio2+ecc3r55Zf1/PPPa968eZKk119/XRkZGdqxY4cefvjhG1stAGDAiOnXgBoaGtTU1KSCgoLwY4FAQHl5eaqu7v5dSR0dHQqFQhEbAGDgi2mAmpqaJEkZGRkRj2dkZISf+7KysjIFAoHwlp2dHcslAQD6KPN3wZWWlqq1tTW8nTx50npJAIBeENMABYNXvgmyubk54vHm5ubwc1/m9/uVkpISsQEABr6YBignJ0fBYFAVFRXhx0KhkA4ePKj8/PxYHgoA0M95fhfcuXPnVFdXF/64oaFBR44cUWpqqkaNGqWVK1fqJz/5icaPH6+cnBy98MILysrK0vz582O5bgBAP+c5QIcOHdIDDzwQ/rikpESStHjxYm3evFnPPvus2tvbtWzZMrW0tOi+++7T7t27NWSI9/uGAQAGLp9zrk/dby8UCikQCGiW5mmQb7D1ckwl3PN1zzP//C+/jsNKujdr5VOeZ27ddjAOK7E1KHuk55nLr3n/z255dpXnmf8yrNXzjCTl1TzqeebiJe/3Nj6c97rnmQl7l3qeGb/4Q88ziN4l16lK7VRra+s1v65v/i44AMDNiQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa8374W+E9t2YmeZ26Nwzq6c+G/To9q7tR3vP+dbNP8jZ5n8v2XPc9sbBnjeeab5f/d84wkZW30fvfoYKX3u9e/+pfxnmcmPFXreabL8wR6A1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJn3POWS/ir4VCIQUCAc3SPA3yeb+54YCS4P1mn3/6kfebcB59/BXPM5LU6bzfUPP/dV2K6lheBaI4d5I0xOf9/rz/eC7oeebXjxZ6nvF93OB5puv8ec8zkuSv8v57+qdx/+J5Zs2Zez3P1NzL35v7ukuuU5XaqdbWVqWkpPS4H3+SAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJ73deRO/p8n6zzzufr/Y8M+OTv/M8I0kLnt7neeZvbjke1bG8+rs/LIpqzvfebZ5ngv/rgyiO9O+eJ3rzrsG/Hrvd80yn834D2D2vzPA8kyrvr3H0TVwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpNOIforu5Y9U/DPU+oylRHcurTH3cK8fp6wbdkdVrx/o/n6V6nkndxI1Fb2ZcAQEATBAgAIAJzwHav3+/HnzwQWVlZcnn82nHjh0Rzy9ZskQ+ny9iKywsjNV6AQADhOcAtbe3Kzc3V+Xl5T3uU1hYqMbGxvC2devWG1okAGDg8fwmhKKiIhUVFV1zH7/fr2AwGPWiAAADX1y+BlRZWan09HRNmDBBTz75pM6ePdvjvh0dHQqFQhEbAGDgi3mACgsL9frrr6uiokI/+9nPVFVVpaKiIl2+fLnb/cvKyhQIBMJbdnZ2rJcEAOiDYv59QA8//HD415MnT9aUKVM0duxYVVZWavbs2VftX1paqpKSkvDHoVCICAHATSDub8MeM2aM0tLSVFdX1+3zfr9fKSkpERsAYOCLe4BOnTqls2fPKjMzM96HAgD0I57/Ce7cuXMRVzMNDQ06cuSIUlNTlZqaqrVr12rhwoUKBoOqr6/Xs88+q3Hjxmnu3LkxXTgAoH/zHKBDhw7pgQceCH/8+ddvFi9erA0bNujo0aN67bXX1NLSoqysLM2ZM0c//vGP5ff7Y7dqAEC/5zlAs2bNknOux+fffffdG1oQgNj5aM0dUc0N8yV5nllV+Yjnmbv0e88zGDi4FxwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMxPxHcgOIj8QJ4zzP7JrzSpRH83437GENg6M8Fm5WXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSnQT/xHUbrnmbsGe7+pqCQ1Xv7M88ydv6r3PHPJ8wQGEq6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwU6Cfa7r3Qa8ea9c/f9zwzvulgHFaCgYwrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjBQy0/Ld8zzO1BX8fh5V0b8Kzf/A80xWHdWBg4woIAGCCAAEATHgKUFlZmaZNm6bk5GSlp6dr/vz5qq2tjdjnwoULKi4u1ogRI3Trrbdq4cKFam5ujumiAQD9n6cAVVVVqbi4WAcOHNCePXvU2dmpOXPmqL29PbzPqlWr9M4772jbtm2qqqrS6dOntWDBgpgvHADQv3l6E8Lu3bsjPt68ebPS09NVU1OjmTNnqrW1Vb/85S+1ZcsWfec735Ekbdq0SV/72td04MABfetb34rdygEA/doNfQ2otbVVkpSamipJqqmpUWdnpwoKCsL7TJw4UaNGjVJ1dXW3n6Ojo0OhUChiAwAMfFEHqKurSytXrtSMGTM0adIkSVJTU5OSkpI0fPjwiH0zMjLU1NTU7ecpKytTIBAIb9nZ2dEuCQDQj0QdoOLiYh07dkxvvvnmDS2gtLRUra2t4e3kyZM39PkAAP1DVN+IumLFCu3atUv79+/XyJEjw48Hg0FdvHhRLS0tEVdBzc3NCgaD3X4uv98vv98fzTIAAP2Ypysg55xWrFih7du3a9++fcrJyYl4furUqRo8eLAqKirCj9XW1urEiRPKz/f+nd8AgIHL0xVQcXGxtmzZop07dyo5OTn8dZ1AIKChQ4cqEAjoiSeeUElJiVJTU5WSkqKnn35a+fn5vAMOABDBU4A2bNggSZo1a1bE45s2bdKSJUskST//+c+VkJCghQsXqqOjQ3PnztUvfvGLmCwWADBweAqQc+66+wwZMkTl5eUqLy+PelHAQPfn2Rd75TiPNcyJaq7rQktsFwJ0g3vBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwERUPxEVwBcSb7vN88zie6vjsJKrNf7PcVHNDes6GOOVAFfjCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSIEb1D5jvOeZH6bt9TyzqL7Q88yt7/7B84wkdUU1BXjDFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkQL9xMfNQc8zoydEeVvRf/uj95muy9EdCzctroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBToJ3ZO3+h5puXtpKiOtXrifZ5nXAc3I4U3XAEBAEwQIACACU8BKisr07Rp05ScnKz09HTNnz9ftbW1EfvMmjVLPp8vYlu+fHlMFw0A6P88BaiqqkrFxcU6cOCA9uzZo87OTs2ZM0ft7e0R+y1dulSNjY3hbd26dTFdNACg//P0JoTdu3dHfLx582alp6erpqZGM2fODD8+bNgwBYPef3ojAODmcUNfA2ptbZUkpaamRjz+xhtvKC0tTZMmTVJpaanOnz/f4+fo6OhQKBSK2AAAA1/Ub8Pu6urSypUrNWPGDE2aNCn8+KOPPqrRo0crKytLR48e1XPPPafa2lq9/fbb3X6esrIyrV27NtplAAD6qagDVFxcrGPHjun999+PeHzZsmXhX0+ePFmZmZmaPXu26uvrNXbs2Ks+T2lpqUpKSsIfh0IhZWdnR7ssAEA/EVWAVqxYoV27dmn//v0aOXLkNffNy8uTJNXV1XUbIL/fL7/fH80yAAD9mKcAOef09NNPa/v27aqsrFROTs51Z44cOSJJyszMjGqBAICByVOAiouLtWXLFu3cuVPJyclqamqSJAUCAQ0dOlT19fXasmWLvvvd72rEiBE6evSoVq1apZkzZ2rKlClx+Q0AAPonTwHasGGDpCvfbPrXNm3apCVLligpKUl79+7Vyy+/rPb2dmVnZ2vhwoV6/vnnY7ZgAMDA4Pmf4K4lOztbVVVVN7QgAMDNgbthAzdo6LtHPM9M/f3fep5pO53seWbEh4meZyRpxMUDUc0BXnAzUgCACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjBW6Q67zoeSZz/sfeZzxPAH0bV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM9Ll7wTnnJEmX1Ck548UAADy7pE5JX/z/vCd9LkBtbW2SpPf1r8YrAQDciLa2NgUCgR6f97nrJaqXdXV16fTp00pOTpbP54t4LhQKKTs7WydPnlRKSorRCu1xHq7gPFzBebiC83BFXzgPzjm1tbUpKytLCQk9f6Wnz10BJSQkaOTIkdfcJyUl5aZ+gX2O83AF5+EKzsMVnIcrrM/Dta58PsebEAAAJggQAMBEvwqQ3+/XmjVr5Pf7rZdiivNwBefhCs7DFZyHK/rTeehzb0IAANwc+tUVEABg4CBAAAATBAgAYIIAAQBM9JsAlZeX684779SQIUOUl5en3/3ud9ZL6nUvvviifD5fxDZx4kTrZcXd/v379eCDDyorK0s+n087duyIeN45p9WrVyszM1NDhw5VQUGBjh8/brPYOLreeViyZMlVr4/CwkKbxcZJWVmZpk2bpuTkZKWnp2v+/Pmqra2N2OfChQsqLi7WiBEjdOutt2rhwoVqbm42WnF8fJXzMGvWrKteD8uXLzdacff6RYDeeustlZSUaM2aNfrwww+Vm5uruXPn6syZM9ZL63V33323Ghsbw9v7779vvaS4a29vV25ursrLy7t9ft26dXrllVe0ceNGHTx4ULfccovmzp2rCxcu9PJK4+t650GSCgsLI14fW7du7cUVxl9VVZWKi4t14MAB7dmzR52dnZozZ47a29vD+6xatUrvvPOOtm3bpqqqKp0+fVoLFiwwXHXsfZXzIElLly6NeD2sW7fOaMU9cP3A9OnTXXFxcfjjy5cvu6ysLFdWVma4qt63Zs0al5uba70MU5Lc9u3bwx93dXW5YDDoXnrppfBjLS0tzu/3u61btxqssHd8+Tw459zixYvdvHnzTNZj5cyZM06Sq6qqcs5d+bMfPHiw27ZtW3ifjz/+2Ely1dXVVsuMuy+fB+ec+/a3v+2+973v2S3qK+jzV0AXL15UTU2NCgoKwo8lJCSooKBA1dXVhiuzcfz4cWVlZWnMmDF67LHHdOLECeslmWpoaFBTU1PE6yMQCCgvL++mfH1UVlYqPT1dEyZM0JNPPqmzZ89aLymuWltbJUmpqamSpJqaGnV2dka8HiZOnKhRo0YN6NfDl8/D59544w2lpaVp0qRJKi0t1fnz5y2W16M+dzPSL/v00091+fJlZWRkRDyekZGhP/7xj0arspGXl6fNmzdrwoQJamxs1Nq1a3X//ffr2LFjSk5Otl6eiaamJknq9vXx+XM3i8LCQi1YsEA5OTmqr6/XD3/4QxUVFam6ulqJiYnWy4u5rq4urVy5UjNmzNCkSZMkXXk9JCUlafjw4RH7DuTXQ3fnQZIeffRRjR49WllZWTp69Kiee+451dbW6u233zZcbaQ+HyB8oaioKPzrKVOmKC8vT6NHj9ZvfvMbPfHEE4YrQ1/w8MMPh389efJkTZkyRWPHjlVlZaVmz55tuLL4KC4u1rFjx26Kr4NeS0/nYdmyZeFfT548WZmZmZo9e7bq6+s1duzY3l5mt/r8P8GlpaUpMTHxqnexNDc3KxgMGq2qbxg+fLjuuusu1dXVWS/FzOevAV4fVxszZozS0tIG5OtjxYoV2rVrl957772IH98SDAZ18eJFtbS0ROw/UF8PPZ2H7uTl5UlSn3o99PkAJSUlaerUqaqoqAg/1tXVpYqKCuXn5xuuzN65c+dUX1+vzMxM66WYycnJUTAYjHh9hEIhHTx48KZ/fZw6dUpnz54dUK8P55xWrFih7du3a9++fcrJyYl4furUqRo8eHDE66G2tlYnTpwYUK+H652H7hw5ckSS+tbrwfpdEF/Fm2++6fx+v9u8ebP76KOP3LJly9zw4cNdU1OT9dJ61fe//31XWVnpGhoa3G9/+1tXUFDg0tLS3JkzZ6yXFldtbW3u8OHD7vDhw06SW79+vTt8+LD75JNPnHPO/fSnP3XDhw93O3fudEePHnXz5s1zOTk57rPPPjNeeWxd6zy0tbW5Z555xlVXV7uGhga3d+9e941vfMONHz/eXbhwwXrpMfPkk0+6QCDgKisrXWNjY3g7f/58eJ/ly5e7UaNGuX379rlDhw65/Px8l5+fb7jq2Lveeairq3M/+tGP3KFDh1xDQ4PbuXOnGzNmjJs5c6bxyiP1iwA559yrr77qRo0a5ZKSktz06dPdgQMHrJfU6xYtWuQyMzNdUlKSu+OOO9yiRYtcXV2d9bLi7r333nOSrtoWL17snLvyVuwXXnjBZWRkOL/f72bPnu1qa2ttFx0H1zoP58+fd3PmzHG33367Gzx4sBs9erRbunTpgPtLWne/f0lu06ZN4X0+++wz99RTT7nbbrvNDRs2zD300EOusbHRbtFxcL3zcOLECTdz5kyXmprq/H6/GzdunPvBD37gWltbbRf+Jfw4BgCAiT7/NSAAwMBEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJj4/0BFqfxp5mvKAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build a simple autoencoder",
   "id": "5a540c2a2d80d51f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:56:58.274148Z",
     "start_time": "2024-08-08T08:56:58.219421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_img = keras.Input(shape=(784,))\n",
    "encoded = keras.layers.Dense(144, activation='relu')(input_img)\n",
    "decoded = keras.layers.Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "encoded_input = keras.Input(shape=(144,))\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ],
   "id": "20a04743484b51e3",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:45:49.488654Z",
     "start_time": "2024-08-08T08:43:08.540764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics='binary_crossentropy')\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))"
   ],
   "id": "84f02013d2cf68c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 3s 10ms/step - loss: 0.2097 - binary_crossentropy: 0.2097 - val_loss: 0.1316 - val_binary_crossentropy: 0.1316\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1138 - binary_crossentropy: 0.1138 - val_loss: 0.0988 - val_binary_crossentropy: 0.0988\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0928 - binary_crossentropy: 0.0928 - val_loss: 0.0860 - val_binary_crossentropy: 0.0860\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0833 - binary_crossentropy: 0.0833 - val_loss: 0.0793 - val_binary_crossentropy: 0.0793\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0780 - binary_crossentropy: 0.0780 - val_loss: 0.0754 - val_binary_crossentropy: 0.0754\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0747 - binary_crossentropy: 0.0747 - val_loss: 0.0730 - val_binary_crossentropy: 0.0730\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0726 - binary_crossentropy: 0.0726 - val_loss: 0.0713 - val_binary_crossentropy: 0.0713\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0712 - binary_crossentropy: 0.0712 - val_loss: 0.0701 - val_binary_crossentropy: 0.0701\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0702 - binary_crossentropy: 0.0702 - val_loss: 0.0693 - val_binary_crossentropy: 0.0693\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.0694 - binary_crossentropy: 0.0694 - val_loss: 0.0686 - val_binary_crossentropy: 0.0686\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0688 - binary_crossentropy: 0.0688 - val_loss: 0.0681 - val_binary_crossentropy: 0.0681\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0683 - binary_crossentropy: 0.0683 - val_loss: 0.0677 - val_binary_crossentropy: 0.0677\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0679 - binary_crossentropy: 0.0679 - val_loss: 0.0674 - val_binary_crossentropy: 0.0674\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0676 - binary_crossentropy: 0.0676 - val_loss: 0.0671 - val_binary_crossentropy: 0.0671\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0673 - binary_crossentropy: 0.0673 - val_loss: 0.0668 - val_binary_crossentropy: 0.0668\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.0670 - binary_crossentropy: 0.0670 - val_loss: 0.0666 - val_binary_crossentropy: 0.0666\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0668 - binary_crossentropy: 0.0668 - val_loss: 0.0665 - val_binary_crossentropy: 0.0665\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0666 - binary_crossentropy: 0.0666 - val_loss: 0.0663 - val_binary_crossentropy: 0.0663\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0665 - binary_crossentropy: 0.0665 - val_loss: 0.0662 - val_binary_crossentropy: 0.0662\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0663 - binary_crossentropy: 0.0663 - val_loss: 0.0661 - val_binary_crossentropy: 0.0661\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.0662 - binary_crossentropy: 0.0662 - val_loss: 0.0659 - val_binary_crossentropy: 0.0659\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0661 - binary_crossentropy: 0.0661 - val_loss: 0.0659 - val_binary_crossentropy: 0.0659\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0660 - binary_crossentropy: 0.0660 - val_loss: 0.0658 - val_binary_crossentropy: 0.0658\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0659 - binary_crossentropy: 0.0659 - val_loss: 0.0657 - val_binary_crossentropy: 0.0657\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0659 - binary_crossentropy: 0.0659 - val_loss: 0.0656 - val_binary_crossentropy: 0.0656\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0658 - binary_crossentropy: 0.0658 - val_loss: 0.0656 - val_binary_crossentropy: 0.0656\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0657 - binary_crossentropy: 0.0657 - val_loss: 0.0655 - val_binary_crossentropy: 0.0655\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0657 - binary_crossentropy: 0.0657 - val_loss: 0.0655 - val_binary_crossentropy: 0.0655\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0656 - binary_crossentropy: 0.0656 - val_loss: 0.0654 - val_binary_crossentropy: 0.0654\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0656 - binary_crossentropy: 0.0656 - val_loss: 0.0654 - val_binary_crossentropy: 0.0654\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0655 - binary_crossentropy: 0.0655 - val_loss: 0.0653 - val_binary_crossentropy: 0.0653\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0655 - binary_crossentropy: 0.0655 - val_loss: 0.0653 - val_binary_crossentropy: 0.0653\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0654 - binary_crossentropy: 0.0654 - val_loss: 0.0653 - val_binary_crossentropy: 0.0653\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0654 - binary_crossentropy: 0.0654 - val_loss: 0.0653 - val_binary_crossentropy: 0.0653\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0654 - binary_crossentropy: 0.0654 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x196e380b5b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualization",
   "id": "8deb9a25dcc65a57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:50:41.497109Z",
     "start_time": "2024-08-08T08:50:40.214559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_imgs = encoder.predict(X_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "plt.subplot(311)\n",
    "plt.imshow(X_test[0].reshape(28, 28))\n",
    "plt.subplot(312)\n",
    "plt.imshow(decoded_imgs[0].reshape(28, 28))\n",
    "plt.subplot(313)\n",
    "plt.imshow(np.uint(encoded_imgs[0].reshape(12, 12)))\n"
   ],
   "id": "873f5988ba5e9be5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x196ea7f8640>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification",
   "id": "aca0086521d7d413"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:03:23.854568Z",
     "start_time": "2024-08-08T08:58:03.219822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train_encoded, x_test_encoded = encoder(X_train), encoder(X_test)\n",
    "print(x_train_encoded.shape)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_encoded, tf.keras.utils.to_categorical(y_train),\n",
    "          validation_data=(x_test_encoded, tf.keras.utils.to_categorical(y_test)),\n",
    "          epochs=100,\n",
    "          batch_size=32)"
   ],
   "id": "9dacdadf0ceed5b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 144)\n",
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1373 - accuracy: 0.7944 - val_loss: 0.0802 - val_accuracy: 0.8842\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0737 - accuracy: 0.8901 - val_loss: 0.0631 - val_accuracy: 0.9075\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0613 - accuracy: 0.9081 - val_loss: 0.0550 - val_accuracy: 0.9179\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0539 - accuracy: 0.9194 - val_loss: 0.0503 - val_accuracy: 0.9259\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0489 - accuracy: 0.9270 - val_loss: 0.0459 - val_accuracy: 0.9333\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0451 - accuracy: 0.9333 - val_loss: 0.0442 - val_accuracy: 0.9355\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0422 - accuracy: 0.9387 - val_loss: 0.0418 - val_accuracy: 0.9386\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0398 - accuracy: 0.9421 - val_loss: 0.0399 - val_accuracy: 0.9412\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0379 - accuracy: 0.9458 - val_loss: 0.0388 - val_accuracy: 0.9433\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0364 - accuracy: 0.9488 - val_loss: 0.0379 - val_accuracy: 0.9449\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0351 - accuracy: 0.9508 - val_loss: 0.0363 - val_accuracy: 0.9489\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0339 - accuracy: 0.9530 - val_loss: 0.0354 - val_accuracy: 0.9498\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0329 - accuracy: 0.9544 - val_loss: 0.0352 - val_accuracy: 0.9487\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0320 - accuracy: 0.9563 - val_loss: 0.0351 - val_accuracy: 0.9509\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0312 - accuracy: 0.9574 - val_loss: 0.0347 - val_accuracy: 0.9508\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0306 - accuracy: 0.9586 - val_loss: 0.0341 - val_accuracy: 0.9530\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0299 - accuracy: 0.9595 - val_loss: 0.0342 - val_accuracy: 0.9543\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0293 - accuracy: 0.9606 - val_loss: 0.0335 - val_accuracy: 0.9538\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0288 - accuracy: 0.9611 - val_loss: 0.0341 - val_accuracy: 0.9517\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0283 - accuracy: 0.9622 - val_loss: 0.0334 - val_accuracy: 0.9533\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0278 - accuracy: 0.9628 - val_loss: 0.0340 - val_accuracy: 0.9512\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0275 - accuracy: 0.9636 - val_loss: 0.0331 - val_accuracy: 0.9530\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0271 - accuracy: 0.9642 - val_loss: 0.0337 - val_accuracy: 0.9525\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0266 - accuracy: 0.9657 - val_loss: 0.0343 - val_accuracy: 0.9536\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0263 - accuracy: 0.9660 - val_loss: 0.0330 - val_accuracy: 0.9548\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0260 - accuracy: 0.9668 - val_loss: 0.0332 - val_accuracy: 0.9529\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0257 - accuracy: 0.9669 - val_loss: 0.0332 - val_accuracy: 0.9544\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0255 - accuracy: 0.9668 - val_loss: 0.0332 - val_accuracy: 0.9535\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0252 - accuracy: 0.9677 - val_loss: 0.0337 - val_accuracy: 0.9536\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0249 - accuracy: 0.9684 - val_loss: 0.0326 - val_accuracy: 0.9548\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0246 - accuracy: 0.9689 - val_loss: 0.0327 - val_accuracy: 0.9536\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0245 - accuracy: 0.9697 - val_loss: 0.0334 - val_accuracy: 0.9537\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0243 - accuracy: 0.9691 - val_loss: 0.0331 - val_accuracy: 0.9552\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0239 - accuracy: 0.9697 - val_loss: 0.0335 - val_accuracy: 0.9542\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0238 - accuracy: 0.9703 - val_loss: 0.0333 - val_accuracy: 0.9550\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0235 - accuracy: 0.9706 - val_loss: 0.0330 - val_accuracy: 0.9551\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9713 - val_loss: 0.0332 - val_accuracy: 0.9559\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0232 - accuracy: 0.9717 - val_loss: 0.0333 - val_accuracy: 0.9548\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0231 - accuracy: 0.9711 - val_loss: 0.0332 - val_accuracy: 0.9563\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0229 - accuracy: 0.9717 - val_loss: 0.0342 - val_accuracy: 0.9535\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0228 - accuracy: 0.9718 - val_loss: 0.0335 - val_accuracy: 0.9555\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0225 - accuracy: 0.9727 - val_loss: 0.0337 - val_accuracy: 0.9560\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0224 - accuracy: 0.9725 - val_loss: 0.0333 - val_accuracy: 0.9568\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0222 - accuracy: 0.9730 - val_loss: 0.0332 - val_accuracy: 0.9559\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0222 - accuracy: 0.9728 - val_loss: 0.0341 - val_accuracy: 0.9559\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0220 - accuracy: 0.9734 - val_loss: 0.0339 - val_accuracy: 0.9560\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0219 - accuracy: 0.9731 - val_loss: 0.0340 - val_accuracy: 0.9555\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0218 - accuracy: 0.9732 - val_loss: 0.0342 - val_accuracy: 0.9564\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0216 - accuracy: 0.9735 - val_loss: 0.0338 - val_accuracy: 0.9565\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0215 - accuracy: 0.9736 - val_loss: 0.0346 - val_accuracy: 0.9549\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0214 - accuracy: 0.9740 - val_loss: 0.0338 - val_accuracy: 0.9575\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0213 - accuracy: 0.9748 - val_loss: 0.0345 - val_accuracy: 0.9555\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0212 - accuracy: 0.9749 - val_loss: 0.0339 - val_accuracy: 0.9569\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0211 - accuracy: 0.9745 - val_loss: 0.0346 - val_accuracy: 0.9562\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0210 - accuracy: 0.9747 - val_loss: 0.0348 - val_accuracy: 0.9561\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0209 - accuracy: 0.9749 - val_loss: 0.0348 - val_accuracy: 0.9555\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0208 - accuracy: 0.9753 - val_loss: 0.0351 - val_accuracy: 0.9560\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0207 - accuracy: 0.9751 - val_loss: 0.0345 - val_accuracy: 0.9568\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0207 - accuracy: 0.9755 - val_loss: 0.0351 - val_accuracy: 0.9549\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0206 - accuracy: 0.9757 - val_loss: 0.0353 - val_accuracy: 0.9537\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0205 - accuracy: 0.9757 - val_loss: 0.0350 - val_accuracy: 0.9545\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0204 - accuracy: 0.9756 - val_loss: 0.0348 - val_accuracy: 0.9557\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0204 - accuracy: 0.9759 - val_loss: 0.0363 - val_accuracy: 0.9532\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0202 - accuracy: 0.9759 - val_loss: 0.0360 - val_accuracy: 0.9553\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0202 - accuracy: 0.9766 - val_loss: 0.0355 - val_accuracy: 0.9559\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0201 - accuracy: 0.9770 - val_loss: 0.0351 - val_accuracy: 0.9559\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0201 - accuracy: 0.9764 - val_loss: 0.0357 - val_accuracy: 0.9557\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0200 - accuracy: 0.9763 - val_loss: 0.0353 - val_accuracy: 0.9551\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0199 - accuracy: 0.9768 - val_loss: 0.0360 - val_accuracy: 0.9557\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0199 - accuracy: 0.9767 - val_loss: 0.0357 - val_accuracy: 0.9560\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0199 - accuracy: 0.9771 - val_loss: 0.0357 - val_accuracy: 0.9559\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0198 - accuracy: 0.9771 - val_loss: 0.0366 - val_accuracy: 0.9541\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0197 - accuracy: 0.9771 - val_loss: 0.0359 - val_accuracy: 0.9562\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0196 - accuracy: 0.9778 - val_loss: 0.0364 - val_accuracy: 0.9546\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0196 - accuracy: 0.9776 - val_loss: 0.0367 - val_accuracy: 0.9532\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0195 - accuracy: 0.9773 - val_loss: 0.0361 - val_accuracy: 0.9558\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0195 - accuracy: 0.9776 - val_loss: 0.0371 - val_accuracy: 0.9536\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0194 - accuracy: 0.9775 - val_loss: 0.0371 - val_accuracy: 0.9540\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0194 - accuracy: 0.9777 - val_loss: 0.0365 - val_accuracy: 0.9551\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0193 - accuracy: 0.9780 - val_loss: 0.0366 - val_accuracy: 0.9542\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0193 - accuracy: 0.9774 - val_loss: 0.0370 - val_accuracy: 0.9547\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0193 - accuracy: 0.9776 - val_loss: 0.0370 - val_accuracy: 0.9548\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0192 - accuracy: 0.9780 - val_loss: 0.0373 - val_accuracy: 0.9551\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0192 - accuracy: 0.9778 - val_loss: 0.0374 - val_accuracy: 0.9544\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0192 - accuracy: 0.9786 - val_loss: 0.0366 - val_accuracy: 0.9545\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0191 - accuracy: 0.9779 - val_loss: 0.0375 - val_accuracy: 0.9541\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0190 - accuracy: 0.9782 - val_loss: 0.0370 - val_accuracy: 0.9539\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0190 - accuracy: 0.9788 - val_loss: 0.0379 - val_accuracy: 0.9537\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0189 - accuracy: 0.9782 - val_loss: 0.0379 - val_accuracy: 0.9552\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0189 - accuracy: 0.9785 - val_loss: 0.0373 - val_accuracy: 0.9547\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0188 - accuracy: 0.9787 - val_loss: 0.0376 - val_accuracy: 0.9558\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0188 - accuracy: 0.9785 - val_loss: 0.0372 - val_accuracy: 0.9542\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0187 - accuracy: 0.9784 - val_loss: 0.0381 - val_accuracy: 0.9551\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0188 - accuracy: 0.9789 - val_loss: 0.0378 - val_accuracy: 0.9553\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0187 - accuracy: 0.9788 - val_loss: 0.0377 - val_accuracy: 0.9555\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 0.9786 - val_loss: 0.0376 - val_accuracy: 0.9555\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 0.9791 - val_loss: 0.0376 - val_accuracy: 0.9547\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 0.9787 - val_loss: 0.0383 - val_accuracy: 0.9547\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0185 - accuracy: 0.9792 - val_loss: 0.0377 - val_accuracy: 0.9543\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0185 - accuracy: 0.9789 - val_loss: 0.0385 - val_accuracy: 0.9552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x196ea8cace0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation of the model",
   "id": "e2b94c58a7306ad1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:08:59.512769Z",
     "start_time": "2024-08-08T09:08:58.623078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pre_te = model.predict(x_test_encoded)\n",
    "print(confusion_matrix(np.argmax(y_pre_te, axis=1), y_test))\n",
    "print(classification_report(np.argmax(y_pre_te, axis=1), y_test))"
   ],
   "id": "f28ff7940e9fd44d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[[ 958    0    6    0    3   10    9    1    6    5]\n",
      " [   0 1119    4    0    3    2    4    4    1    6]\n",
      " [   1    1  977    8    3    1    3   14   12    2]\n",
      " [   2    4   13  975    2   15    0    5   29    8]\n",
      " [   3    0    4    0  934    1    4    4    6   17]\n",
      " [   3    0    1    9    1  833    5    3    7    5]\n",
      " [   5    5    3    1    6   10  931    0    3    0]\n",
      " [   4    2   12    5    4    4    0  980    6    7]\n",
      " [   3    4   12    6    2    7    1    2  895    9]\n",
      " [   1    0    0    6   24    9    1   15    9  950]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       998\n",
      "           1       0.99      0.98      0.98      1143\n",
      "           2       0.95      0.96      0.95      1022\n",
      "           3       0.97      0.93      0.95      1053\n",
      "           4       0.95      0.96      0.96       973\n",
      "           5       0.93      0.96      0.95       867\n",
      "           6       0.97      0.97      0.97       964\n",
      "           7       0.95      0.96      0.96      1024\n",
      "           8       0.92      0.95      0.93       941\n",
      "           9       0.94      0.94      0.94      1015\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.95      0.96      0.95     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Brest Cancer Prediction With Auto Encoders",
   "id": "f8418d59cee7702c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "1b15df5541d83978"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:12:37.152621Z",
     "start_time": "2024-08-08T09:12:37.114251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "X_train, X_test = scaler.fit_transform(X_train), scaler.fit_transform(X_test)"
   ],
   "id": "a6fa126960ad3800",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:13:09.511878Z",
     "start_time": "2024-08-08T09:13:09.493406Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape",
   "id": "6e01cf466d1fd7d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 30)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:17:43.835325Z",
     "start_time": "2024-08-08T09:17:43.787232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_m = keras.Input(shape=(30,))\n",
    "encoded = keras.layers.Dense(2, activation='sigmoid')(input_m)\n",
    "decoded = keras.layers.Dense(30, activation='linear')(encoded)\n",
    "autoencoder = keras.Model(input_m, decoded)\n",
    "encoder = keras.Model(input_m, encoded)\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "encoded_input = keras.Input(shape=(2,))\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ],
   "id": "846babebf6cfcc3f",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:19:40.124071Z",
     "start_time": "2024-08-08T09:19:19.781633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse', metrics='mse')\n",
    "autoencoder.fit(X_train, X_train, epochs=100, batch_size=5, shuffle=True, validation_data=(X_test, X_test))"
   ],
   "id": "20ab850944d90361",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.1004 - mse: 0.1004 - val_loss: 0.0779 - val_mse: 0.0779\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0291 - val_mse: 0.0291\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0156 - val_mse: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19757ff29e0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:20:20.670048Z",
     "start_time": "2024-08-08T09:20:20.636371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_x_test = encoder(X_test)\n",
    "encoded_x_train = encoder(X_train)"
   ],
   "id": "abb85bcfa83bae16",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:20:54.648831Z",
     "start_time": "2024-08-08T09:20:31.040870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = keras.models.Sequential()\n",
    "classifier.add(keras.layers.Dense(5, activation = 'relu'))\n",
    "classifier.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "classifier.fit(encoded_x_train, y_train, validation_data = (encoded_x_test, y_test), epochs = 100, batch_size = 5 )"
   ],
   "id": "696d446c07ca8fad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.6700 - accuracy: 0.7085 - val_loss: 0.6851 - val_accuracy: 0.6082\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.7111 - val_loss: 0.6789 - val_accuracy: 0.6082\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.7136 - val_loss: 0.6728 - val_accuracy: 0.6082\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.7136 - val_loss: 0.6668 - val_accuracy: 0.6082\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.7211 - val_loss: 0.6606 - val_accuracy: 0.6199\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.7312 - val_loss: 0.6528 - val_accuracy: 0.6316\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.7462 - val_loss: 0.6450 - val_accuracy: 0.6374\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.7538 - val_loss: 0.6359 - val_accuracy: 0.6374\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7839 - val_loss: 0.6277 - val_accuracy: 0.6374\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7990 - val_loss: 0.6178 - val_accuracy: 0.6374\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.8065 - val_loss: 0.6069 - val_accuracy: 0.6433\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.8241 - val_loss: 0.5956 - val_accuracy: 0.6550\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.8266 - val_loss: 0.5848 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.8291 - val_loss: 0.5735 - val_accuracy: 0.6901\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.8367 - val_loss: 0.5611 - val_accuracy: 0.7135\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.8392 - val_loss: 0.5524 - val_accuracy: 0.7193\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8392 - val_loss: 0.5416 - val_accuracy: 0.7310\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.8417 - val_loss: 0.5286 - val_accuracy: 0.7427\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8492 - val_loss: 0.5170 - val_accuracy: 0.7544\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8543 - val_loss: 0.5064 - val_accuracy: 0.7719\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.8543 - val_loss: 0.4930 - val_accuracy: 0.7953\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8568 - val_loss: 0.4824 - val_accuracy: 0.8012\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8668 - val_loss: 0.4709 - val_accuracy: 0.8012\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8693 - val_loss: 0.4627 - val_accuracy: 0.8070\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8693 - val_loss: 0.4518 - val_accuracy: 0.8129\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8693 - val_loss: 0.4440 - val_accuracy: 0.8129\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8769 - val_loss: 0.4312 - val_accuracy: 0.8187\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8744 - val_loss: 0.4245 - val_accuracy: 0.8187\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8794 - val_loss: 0.4133 - val_accuracy: 0.8187\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8769 - val_loss: 0.4063 - val_accuracy: 0.8187\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8894 - val_loss: 0.3949 - val_accuracy: 0.8304\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8920 - val_loss: 0.3886 - val_accuracy: 0.8246\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8970 - val_loss: 0.3798 - val_accuracy: 0.8363\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8995 - val_loss: 0.3733 - val_accuracy: 0.8363\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8995 - val_loss: 0.3657 - val_accuracy: 0.8363\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8995 - val_loss: 0.3565 - val_accuracy: 0.8480\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.8995 - val_loss: 0.3519 - val_accuracy: 0.8480\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8995 - val_loss: 0.3465 - val_accuracy: 0.8480\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.9020 - val_loss: 0.3357 - val_accuracy: 0.8538\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.9020 - val_loss: 0.3340 - val_accuracy: 0.8538\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.9020 - val_loss: 0.3280 - val_accuracy: 0.8538\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8995 - val_loss: 0.3216 - val_accuracy: 0.8596\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.8995 - val_loss: 0.3163 - val_accuracy: 0.8596\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.8970 - val_loss: 0.3118 - val_accuracy: 0.8596\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.8970 - val_loss: 0.3056 - val_accuracy: 0.8772\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.8995 - val_loss: 0.3026 - val_accuracy: 0.8772\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2625 - accuracy: 0.9020 - val_loss: 0.2947 - val_accuracy: 0.8772\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.8970 - val_loss: 0.2927 - val_accuracy: 0.8772\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.9045 - val_loss: 0.2849 - val_accuracy: 0.8772\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.9045 - val_loss: 0.2823 - val_accuracy: 0.8772\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.9045 - val_loss: 0.2802 - val_accuracy: 0.8772\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2425 - accuracy: 0.9045 - val_loss: 0.2745 - val_accuracy: 0.8772\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2391 - accuracy: 0.9045 - val_loss: 0.2722 - val_accuracy: 0.8772\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.9095 - val_loss: 0.2654 - val_accuracy: 0.8772\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2326 - accuracy: 0.9121 - val_loss: 0.2659 - val_accuracy: 0.8772\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2295 - accuracy: 0.9070 - val_loss: 0.2622 - val_accuracy: 0.8772\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2266 - accuracy: 0.9146 - val_loss: 0.2582 - val_accuracy: 0.8772\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2236 - accuracy: 0.9146 - val_loss: 0.2550 - val_accuracy: 0.8772\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.9095 - val_loss: 0.2540 - val_accuracy: 0.8772\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2185 - accuracy: 0.9121 - val_loss: 0.2490 - val_accuracy: 0.8830\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2161 - accuracy: 0.9121 - val_loss: 0.2454 - val_accuracy: 0.8830\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2137 - accuracy: 0.9095 - val_loss: 0.2457 - val_accuracy: 0.8830\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2111 - accuracy: 0.9121 - val_loss: 0.2450 - val_accuracy: 0.8830\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.9171 - val_loss: 0.2387 - val_accuracy: 0.8830\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2069 - accuracy: 0.9121 - val_loss: 0.2354 - val_accuracy: 0.8889\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2047 - accuracy: 0.9171 - val_loss: 0.2335 - val_accuracy: 0.8889\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.9171 - val_loss: 0.2325 - val_accuracy: 0.8889\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9171 - val_loss: 0.2305 - val_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9196 - val_loss: 0.2309 - val_accuracy: 0.8889\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9171 - val_loss: 0.2269 - val_accuracy: 0.8947\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9171 - val_loss: 0.2259 - val_accuracy: 0.8947\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9221 - val_loss: 0.2210 - val_accuracy: 0.9006\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9171 - val_loss: 0.2226 - val_accuracy: 0.8947\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9171 - val_loss: 0.2170 - val_accuracy: 0.9006\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1890 - accuracy: 0.9171 - val_loss: 0.2169 - val_accuracy: 0.9006\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1876 - accuracy: 0.9171 - val_loss: 0.2173 - val_accuracy: 0.8947\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9171 - val_loss: 0.2150 - val_accuracy: 0.9006\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9171 - val_loss: 0.2137 - val_accuracy: 0.9006\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9146 - val_loss: 0.2109 - val_accuracy: 0.9006\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1833 - accuracy: 0.9171 - val_loss: 0.2102 - val_accuracy: 0.9006\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1813 - accuracy: 0.9171 - val_loss: 0.2096 - val_accuracy: 0.9006\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9146 - val_loss: 0.2065 - val_accuracy: 0.9064\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9171 - val_loss: 0.2055 - val_accuracy: 0.9064\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9271 - val_loss: 0.2025 - val_accuracy: 0.9064\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9271 - val_loss: 0.2065 - val_accuracy: 0.9064\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9171 - val_loss: 0.2048 - val_accuracy: 0.9064\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9271 - val_loss: 0.2024 - val_accuracy: 0.9064\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9246 - val_loss: 0.2002 - val_accuracy: 0.9064\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1733 - accuracy: 0.9246 - val_loss: 0.2002 - val_accuracy: 0.9064\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9271 - val_loss: 0.2009 - val_accuracy: 0.9064\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9246 - val_loss: 0.2013 - val_accuracy: 0.9064\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9246 - val_loss: 0.1995 - val_accuracy: 0.9064\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9246 - val_loss: 0.1971 - val_accuracy: 0.9064\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9296 - val_loss: 0.1946 - val_accuracy: 0.9064\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9271 - val_loss: 0.2008 - val_accuracy: 0.9064\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9271 - val_loss: 0.1942 - val_accuracy: 0.9064\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9271 - val_loss: 0.1952 - val_accuracy: 0.9064\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9246 - val_loss: 0.1947 - val_accuracy: 0.9064\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9271 - val_loss: 0.1939 - val_accuracy: 0.9064\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9271 - val_loss: 0.1944 - val_accuracy: 0.9064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19758112e30>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T09:20:54.790471Z",
     "start_time": "2024-08-08T09:20:54.650829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pre = classifier.predict(encoded_x_test)\n",
    "y_pre[y_pre >= 0.5] = 1\n",
    "y_pre[y_pre < 0.5] = 0\n",
    "print(confusion_matrix(y_pre, y_test))\n",
    "print(classification_report(y_pre, y_test))"
   ],
   "id": "8cb8f9a581e92f11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n",
      "[[ 52   0]\n",
      " [ 16 103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      1.00      0.87        52\n",
      "         1.0       1.00      0.87      0.93       119\n",
      "\n",
      "    accuracy                           0.91       171\n",
      "   macro avg       0.88      0.93      0.90       171\n",
      "weighted avg       0.93      0.91      0.91       171\n",
      "\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a838f5d624b2936"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
